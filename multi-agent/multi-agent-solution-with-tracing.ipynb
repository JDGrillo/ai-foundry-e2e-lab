{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0fdc739",
   "metadata": {},
   "source": [
    "# Multi-Agent Ticket Triage System\n",
    "\n",
    "This notebook demonstrates how to build a **multi-agent system** using Azure AI Agent Service for automated ticket triage. The system uses multiple specialized agents that work together to analyze support tickets and determine:\n",
    "\n",
    "- **Priority Level** (High/Medium/Low)\n",
    "- **Team Assignment** (Frontend/Backend/Infrastructure/Marketing)\n",
    "- **Effort Estimation** (Small/Medium/Large)\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "The system consists of:\n",
    "1. **Three Specialist Agents**: Each focused on one aspect of ticket analysis\n",
    "2. **One Orchestrator Agent**: Uses the specialist agents as tools to provide comprehensive triage\n",
    "3. **Connected Agent Tools**: Enable the orchestrator to call specialist agents as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0bda3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.agents import AgentsClient\n",
    "from azure.ai.agents.models import ConnectedAgentTool, MessageRole, ListSortOrder, ToolSet, FunctionTool\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "project_endpoint = os.getenv(\"AZURE_AI_PROJECT_ENDPOINT\")\n",
    "model_deployment = os.getenv(\"MODEL_DEPLOYMENT_NAME\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ded4b0",
   "metadata": {},
   "source": [
    "## üîç Observability & Tracing Setup\n",
    "\n",
    "To monitor our multi-agent system's performance and behavior, we'll set up Azure AI Foundry tracing. This will help us:\n",
    "\n",
    "- **Track agent interactions**: See how the orchestrator calls each specialist agent\n",
    "- **Monitor response times**: Understand the performance of each agent\n",
    "- **Debug issues**: Trace the flow of data through the multi-agent system\n",
    "- **Analyze usage**: Monitor token consumption and API calls\n",
    "\n",
    "The tracing will capture:\n",
    "1. Each specialist agent call (priority, team, effort assessment)\n",
    "2. The orchestrator agent's decision-making process\n",
    "3. Token usage and response times\n",
    "4. Any errors or issues in the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560febfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install required packages for Azure AI Foundry tracing\n",
    "# %pip install azure-monitor-opentelemetry opentelemetry-instrumentation-openai-v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7a67b6",
   "metadata": {},
   "source": [
    "### Configure OpenTelemetry Instrumentation\n",
    "\n",
    "This cell sets up the telemetry configuration to capture detailed information about our multi-agent system interactions. We enable content recording to see the actual messages exchanged between agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba3941d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference.tracing import AIInferenceInstrumentor\n",
    "\n",
    "# Enable content recording for detailed trace information\n",
    "os.environ[\"OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT\"] = \"true\"\n",
    "os.environ[\"AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED\"] = \"true\"\n",
    "\n",
    "# Configure Azure SDK to use OpenTelemetry\n",
    "os.environ[\"AZURE_SDK_TRACING_IMPLEMENTATION\"] = \"opentelemetry\"\n",
    "\n",
    "# Instrument OpenAI SDK first\n",
    "try:\n",
    "    from opentelemetry.instrumentation.openai_v2 import OpenAIInstrumentor\n",
    "    OpenAIInstrumentor().instrument()\n",
    "    print(\"‚úÖ OpenAI v2 instrumentation enabled.\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è opentelemetry-instrumentation-openai-v2 not available\")\n",
    "\n",
    "# Then instrument Azure AI Inference\n",
    "AIInferenceInstrumentor().instrument()\n",
    "print(\"‚úÖ Azure AI Inference instrumentation enabled.\")\n",
    "print(\"‚úÖ Content recording enabled for multi-agent traces.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859e3e7c",
   "metadata": {},
   "source": [
    "### Configure Azure Monitor Tracing\n",
    "\n",
    "This cell sets up Azure Monitor integration to send our multi-agent system traces to Azure AI Foundry. The traces will be visible in the Tracing tab of your AI Foundry project, allowing you to monitor the complete workflow of the ticket triage process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26abba64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Create AI Project client for telemetry\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=project_endpoint,\n",
    "    credential=DefaultAzureCredential(\n",
    "        exclude_environment_credential=True, \n",
    "        exclude_managed_identity_credential=True\n",
    "    )\n",
    ")\n",
    "\n",
    "# Get Application Insights connection string - following Microsoft's recommended approach\n",
    "print(\"üîß Attempting to get Application Insights connection string...\")\n",
    "try:\n",
    "    connection_string = project_client.telemetry.get_connection_string()\n",
    "    if connection_string:\n",
    "        print(\"‚úÖ Found App Insights connection string!\")\n",
    "        print(f\"üîó Connection string format: {connection_string[:50]}...\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No connection string returned from project client.\")\n",
    "        connection_string = None\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error getting App Insights connection string: {e}\")\n",
    "    connection_string = None\n",
    "\n",
    "# Configure Azure Monitor following Microsoft's exact approach from the documentation\n",
    "if connection_string:\n",
    "    try:\n",
    "        print(\"üîß Configuring Azure Monitor for multi-agent tracing...\")\n",
    "        \n",
    "        # Use manual Azure Monitor setup to avoid logging_formatter issues\n",
    "        from azure.monitor.opentelemetry.exporter import AzureMonitorTraceExporter\n",
    "        from opentelemetry.sdk.trace import TracerProvider\n",
    "        from opentelemetry.sdk.trace.export import BatchSpanProcessor\n",
    "        from opentelemetry import trace\n",
    "        \n",
    "        # Create new tracer provider\n",
    "        tracer_provider = TracerProvider()\n",
    "        trace.set_tracer_provider(tracer_provider)\n",
    "        \n",
    "        # Add Azure Monitor exporter\n",
    "        azure_exporter = AzureMonitorTraceExporter(connection_string=connection_string)\n",
    "        span_processor = BatchSpanProcessor(azure_exporter)\n",
    "        tracer_provider.add_span_processor(span_processor)\n",
    "        \n",
    "        print(\"‚úÖ Azure Monitor configured successfully!\")\n",
    "        print(\"üéØ Multi-agent traces will be visible in Azure AI Foundry portal!\")\n",
    "        \n",
    "    except Exception as config_error:\n",
    "        print(f\"‚ùå Azure Monitor configuration failed: {config_error}\")\n",
    "        print(\"üí° Proceeding without Azure Monitor tracing\")\n",
    "        \n",
    "        # Set up basic tracer provider as fallback\n",
    "        from opentelemetry.sdk.trace import TracerProvider\n",
    "        from opentelemetry import trace\n",
    "        tracer_provider = TracerProvider()\n",
    "        trace.set_tracer_provider(tracer_provider)\n",
    "        print(\"‚úÖ Basic tracing provider configured as fallback\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot configure Azure Monitor without connection string.\")\n",
    "    print(\"üí° Please ensure Application Insights is properly configured in your AI Foundry project.\")\n",
    "    \n",
    "    # Set up basic tracer provider as fallback\n",
    "    from opentelemetry.sdk.trace import TracerProvider\n",
    "    from opentelemetry import trace\n",
    "    tracer_provider = TracerProvider()\n",
    "    trace.set_tracer_provider(tracer_provider)\n",
    "    print(\"‚úÖ Basic tracing provider configured - spans will be created but not exported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1459cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Priority agent definition\n",
    "priority_agent_name = \"priority_agent\"\n",
    "priority_agent_instructions = \"\"\"\n",
    "Assess how urgent a ticket is based on its description.\n",
    "\n",
    "Respond with one of the following levels:\n",
    "- High: User-facing or blocking issues\n",
    "- Medium: Time-sensitive but not breaking anything\n",
    "- Low: Cosmetic or non-urgent tasks\n",
    "\n",
    "Only output the urgency level and a very brief explanation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304909cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team agent definition\n",
    "team_agent_name = \"team_agent\"\n",
    "team_agent_instructions = \"\"\"\n",
    "Decide which team should own each ticket.\n",
    "\n",
    "Choose from the following teams:\n",
    "- Frontend\n",
    "- Backend\n",
    "- Infrastructure\n",
    "- Marketing\n",
    "\n",
    "Base your answer on the content of the ticket. Respond with the team name and a very brief explanation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcd68a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effort agent definition\n",
    "effort_agent_name = \"effort_agent\"\n",
    "effort_agent_instructions = \"\"\"\n",
    "Estimate how much work each ticket will require.\n",
    "\n",
    "Use the following scale:\n",
    "- Small: Can be completed in a day\n",
    "- Medium: 2-3 days of work\n",
    "- Large: Multi-day or cross-team effort\n",
    "\n",
    "Base your estimate on the complexity implied by the ticket. Respond with the effort level and a brief justification.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1e5233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instructions for the primary agent\n",
    "triage_agent_instructions = \"\"\"\n",
    "Triage the given ticket. Use the connected tools to determine the ticket's priority, \n",
    "which team it should be assigned to, and how much effort it may take.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d190154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the agents client\n",
    "agents_client = AgentsClient(\n",
    "endpoint=project_endpoint,\n",
    "credential=DefaultAzureCredential(\n",
    "    exclude_environment_credential=True, \n",
    "    exclude_managed_identity_credential=True\n",
    "),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09922fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXED: Create agents without context manager to keep client active\n",
    "print(\"Creating agents...\")\n",
    "\n",
    "# Create the priority agent on the Azure AI agent service\n",
    "priority_agent = agents_client.create_agent(\n",
    "    model=model_deployment,\n",
    "    name=priority_agent_name,\n",
    "    instructions=priority_agent_instructions\n",
    ")\n",
    "print(\"‚úÖ Priority agent created\")\n",
    "\n",
    "# Create a connected agent tool for the priority agent\n",
    "priority_agent_tool = ConnectedAgentTool(\n",
    "    id=priority_agent.id, \n",
    "    name=priority_agent_name, \n",
    "    description=\"Assess the priority of a ticket\"\n",
    ")\n",
    "\n",
    "# Create the team agent and connected tool\n",
    "team_agent = agents_client.create_agent(\n",
    "    model=model_deployment,\n",
    "    name=team_agent_name,\n",
    "    instructions=team_agent_instructions\n",
    ")\n",
    "print(\"‚úÖ Team agent created\")\n",
    "\n",
    "team_agent_tool = ConnectedAgentTool(\n",
    "    id=team_agent.id, \n",
    "    name=team_agent_name, \n",
    "    description=\"Determines which team should take the ticket\"\n",
    ")\n",
    "\n",
    "# Create the effort agent and connected tool\n",
    "effort_agent = agents_client.create_agent(\n",
    "    model=model_deployment,\n",
    "    name=effort_agent_name,\n",
    "    instructions=effort_agent_instructions\n",
    ")\n",
    "print(\"‚úÖ Effort agent created\")\n",
    "\n",
    "effort_agent_tool = ConnectedAgentTool(\n",
    "    id=effort_agent.id, \n",
    "    name=effort_agent_name, \n",
    "    description=\"Determines the effort required to complete the ticket\"\n",
    ")\n",
    "\n",
    "# Create a main agent with the Connected Agent tools\n",
    "agent = agents_client.create_agent(\n",
    "    model=model_deployment,\n",
    "    name=\"triage-agent\",\n",
    "    instructions=triage_agent_instructions,\n",
    "    tools=[\n",
    "        priority_agent_tool.definitions[0],\n",
    "        team_agent_tool.definitions[0],\n",
    "        effort_agent_tool.definitions[0]\n",
    "    ]\n",
    ")\n",
    "print(\"‚úÖ Main triage agent created with connected tools\")\n",
    "print(\"üéØ All agents are ready for use!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d424d529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create thread for the chat session\n",
    "print(\"Creating agent thread.\")\n",
    "thread = agents_client.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690692bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry import trace\n",
    "import time\n",
    "\n",
    "# Get tracer for custom span creation - following Microsoft's example\n",
    "tracer = trace.get_tracer(__name__)\n",
    "\n",
    "# Create the ticket prompt\n",
    "prompt = \"Users can't reset their password from the mobile app.\"\n",
    "\n",
    "# Start main tracing span for the entire multi-agent workflow\n",
    "with tracer.start_as_current_span(\"multi_agent_ticket_triage\") as span:\n",
    "    # Add custom attributes as shown in Microsoft docs\n",
    "    span.set_attribute(\"operation.type\", \"ticket_triage\")\n",
    "    span.set_attribute(\"operation.category\", \"multi_agent\")\n",
    "    span.set_attribute(\"ticket.content\", prompt)\n",
    "    span.set_attribute(\"system.agents.count\", 4)  # 3 specialists + 1 orchestrator\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Send a prompt to the agent\n",
    "    message = agents_client.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=MessageRole.USER,\n",
    "        content=prompt,\n",
    "    )\n",
    "    print(f\"üìù Created user message: {prompt}\")\n",
    "    \n",
    "    # Create and process Agent run in thread with tools\n",
    "    print(\"üîÑ Processing multi-agent thread. Please wait...\")\n",
    "    run = agents_client.runs.create_and_process(thread_id=thread.id, agent_id=agent.id)\n",
    "    \n",
    "    # Add run information to span\n",
    "    span.set_attribute(\"run.id\", run.id)\n",
    "    span.set_attribute(\"run.status\", run.status)\n",
    "    span.set_attribute(\"thread.id\", thread.id)\n",
    "    span.set_attribute(\"agent.id\", agent.id)\n",
    "    \n",
    "    if run.status == \"failed\":\n",
    "        span.set_attribute(\"run.error\", str(run.last_error))\n",
    "        print(f\"‚ùå Run failed: {run.last_error}\")\n",
    "    else:\n",
    "        print(\"‚úÖ Multi-agent processing completed successfully\")\n",
    "\n",
    "    # Fetch and analyze all messages\n",
    "    messages = agents_client.messages.list(thread_id=thread.id, order=ListSortOrder.ASCENDING)\n",
    "    \n",
    "    message_count = 0\n",
    "    agent_calls = 0\n",
    "    \n",
    "    print(\"\\nüìä Multi-Agent Conversation Flow:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for message in messages:\n",
    "        if message.text_messages:\n",
    "            message_count += 1\n",
    "            last_msg = message.text_messages[-1]\n",
    "            \n",
    "            # Count specialist agent calls by looking for tool calls in assistant messages\n",
    "            if message.role.lower() == \"assistant\":\n",
    "                msg_content = last_msg.text.value.lower()\n",
    "                if any(agent_name in msg_content for agent_name in [\"priority_agent\", \"team_agent\", \"effort_agent\"]):\n",
    "                    agent_calls += 1\n",
    "            \n",
    "            print(f\"ü§ñ {message.role.upper()}:\")\n",
    "            print(f\"{last_msg.text.value}\\n\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    total_duration = end_time - start_time\n",
    "    \n",
    "    # Add response metadata to span following Microsoft's pattern\n",
    "    span.set_attribute(\"workflow.duration_seconds\", round(total_duration, 2))\n",
    "    span.set_attribute(\"workflow.messages_processed\", message_count)\n",
    "    span.set_attribute(\"workflow.specialist_calls\", agent_calls)\n",
    "    span.set_attribute(\"workflow.status\", \"completed\" if run.status != \"failed\" else \"failed\")\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(f\"üìà Workflow Summary:\")\n",
    "    print(f\"   ‚è±Ô∏è  Total Duration: {total_duration:.2f} seconds\")\n",
    "    print(f\"   üí¨ Messages Processed: {message_count}\")\n",
    "    print(f\"   ü§ñ Specialist Agent Calls: {agent_calls}\")\n",
    "    print(f\"   ‚úÖ Status: {'Completed' if run.status != 'failed' else 'Failed'}\")\n",
    "\n",
    "print(\"\\nüéØ Multi-agent workflow trace completed!\")\n",
    "print(\"üìä Trace should now be visible in Azure AI Foundry portal!\")\n",
    "print(\"   Navigate to: Your Project ‚Üí Tracing tab\")\n",
    "print(\"   Look for a trace with operation name 'multi_agent_ticket_triage'\")\n",
    "print(\"\\nüí° If traces don't appear:\")\n",
    "print(\"   1. Wait 2-5 minutes for propagation\")\n",
    "print(\"   2. Check Application Insights directly in Azure Portal\")\n",
    "print(\"   3. Verify OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT=true is set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf884ae",
   "metadata": {},
   "source": [
    "## üéØ Execute Multi-Agent Ticket Triage with Tracing\n",
    "\n",
    "Now we'll execute our multi-agent ticket triage system with full observability. This will create a comprehensive trace showing:\n",
    "\n",
    "1. **Main triage operation**: The overall ticket analysis process\n",
    "2. **Specialist agent calls**: Each agent's individual assessment (priority, team, effort)\n",
    "3. **Token usage**: Tracking resource consumption across all agents\n",
    "4. **Timing information**: Performance metrics for each step\n",
    "5. **Message flow**: The complete conversation between agents\n",
    "\n",
    "The traces will help us understand how the agents collaborate and optimize the system's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234c6ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the agent when done\n",
    "print(\"Cleaning up agents:\")\n",
    "agents_client.delete_agent(agent.id)\n",
    "print(\"Deleted triage agent.\")\n",
    "\n",
    "# Delete the connected agents when done\n",
    "agents_client.delete_agent(priority_agent.id)\n",
    "print(\"Deleted priority agent.\")\n",
    "agents_client.delete_agent(team_agent.id)\n",
    "print(\"Deleted team agent.\")\n",
    "agents_client.delete_agent(effort_agent.id)\n",
    "print(\"Deleted effort agent.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043666fd",
   "metadata": {},
   "source": [
    "## üìä Viewing and Analyzing Traces\n",
    "\n",
    "After running the multi-agent system, you can view detailed traces in several ways:\n",
    "\n",
    "### üåê Azure AI Foundry Portal\n",
    "1. Navigate to your AI Foundry project\n",
    "2. Click on the **Tracing** tab\n",
    "3. Look for traces with operation name `ticket_triage_workflow`\n",
    "4. Explore the trace hierarchy to see:\n",
    "   - Main workflow span\n",
    "   - Individual specialist agent calls\n",
    "   - Message creation and processing\n",
    "   - Response analysis\n",
    "\n",
    "### üîç What to Look For in Traces\n",
    "- **Performance bottlenecks**: Which agent takes longest to respond?\n",
    "- **Token usage**: How many tokens each specialist agent consumes\n",
    "- **Error patterns**: Any failures in the multi-agent workflow\n",
    "- **Agent collaboration**: The sequence of specialist agent calls\n",
    "- **Message flow**: Complete conversation between user and agents\n",
    "\n",
    "### üìà Key Metrics to Monitor\n",
    "- **Total workflow duration**: End-to-end processing time\n",
    "- **Individual agent response times**: Performance of each specialist\n",
    "- **Token consumption**: Cost optimization opportunities\n",
    "- **Success rates**: Percentage of successful triage operations\n",
    "- **Message count**: Efficiency of agent communication\n",
    "\n",
    "### üí° Optimization Insights\n",
    "The traces can help you:\n",
    "- Identify slow agents that need optimization\n",
    "- Optimize prompt engineering for better performance\n",
    "- Monitor resource usage across the multi-agent system\n",
    "- Debug issues in agent coordination"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "end-to-end-ai-foundry-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
